"""
BGE (BAAI General Embedding) embedder with OpenVINO optimization.

Provides high-quality 768-dimensional embeddings optimized for Intel hardware.
"""

from typing import List, Optional, Union
import numpy as np
from pathlib import Path
from loguru import logger

try:
    from optimum.intel import OVModelForFeatureExtraction
    from transformers import AutoTokenizer
    OPENVINO_AVAILABLE = True
except ImportError:
    OPENVINO_AVAILABLE = False
    logger.warning("OpenVINO not installed. BGE embedder will not be available.")

from src.core.config import get_settings
from src.core.exceptions import EmbeddingError


class BGEEmbedder:
    """
    BGE Re-ranker embedder with OpenVINO optimization.
    
    Features:
    - 768-dimensional embeddings
    - OpenVINO INT8 quantization for speed
    - Batch processing support
    - Automatic model loading from configured path
    
    Performance:
    - ~2-3x faster than PyTorch on CPU
    - Low memory footprint with INT8
    """
    
    def __init__(
        self,
        model_path: Optional[str] = None,
        device: str = "CPU"
    ):
        """
        Initialize BGE embedder.
        
        Args:
            model_path: Path to OpenVINO model directory
            device: Device to use (CPU, GPU, etc.)
        """
        if not OPENVINO_AVAILABLE:
            raise EmbeddingError("OpenVINO not available - install optimum[openvino]")
        
        self.settings = get_settings()
        self.model_path = model_path or self._get_default_model_path()
        self.device = device
        self.model = None
        self.tokenizer = None
        self.dimension = 768  # BGE output dimension
        
        self._load_model()
    
    def _get_default_model_path(self) -> str:
        """Get default BGE model path from config or models directory"""
        # Check if model exists in models directory
        default_path = Path("models/bge-reranker-ov")
        if default_path.exists():
            return str(default_path)
        
        raise EmbeddingError(
            f"BGE model not found at {default_path}. "
            "Please download the model first."
        )
    
    def _load_model(self):
        """Load OpenVINO-optimized BGE model"""
        try:
            logger.info(f"Loading BGE model from {self.model_path}")
            
            # Load tokenizer
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
            
            # Load OpenVINO model
            self.model = OVModelForFeatureExtraction.from_pretrained(
                self.model_path,
                device=self.device
            )
            
            logger.info(f"âœ… BGE model loaded successfully on {self.device}")
            logger.info(f"   Dimension: {self.dimension}")
            
        except Exception as e:
            raise EmbeddingError(f"Failed to load BGE model: {e}")
    
    def embed(
        self,
        texts: Union[str, List[str]],
        normalize: bool = True
    ) -> np.ndarray:
        """
        Generate embeddings for text(s).
        
        Args:
            texts: Single text or list of texts
            normalize: Whether to L2-normalize embeddings
            
        Returns:
            Numpy array of shape (n_texts, 768)
        """
        if isinstance(texts, str):
            texts = [texts]
        
        if not texts:
            raise EmbeddingError("No texts provided for embedding")
        
        try:
            # Tokenize
            inputs = self.tokenizer(
                texts,
                padding=True,
                truncation=True,
                max_length=512,
                return_tensors="pt"
            )
            
            # Generate embeddings
            outputs = self.model(**inputs)
            
            # Mean pooling (take mean of all token embeddings)
            embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()
            
            # Normalize if requested
            if normalize:
                embeddings = self._normalize(embeddings)
            
            return embeddings
            
        except Exception as e:
            raise EmbeddingError(f"Failed to generate embeddings: {e}")
    
    def embed_single(
        self,
        text: str,
        normalize: bool = True
    ) -> np.ndarray:
        """
        Generate embedding for single text.
        
        Args:
            text: Text to embed
            normalize: Whether to L2-normalize
            
        Returns:
            1D numpy array of shape (768,)
        """
        embeddings = self.embed([text], normalize=normalize)
        return embeddings[0]
    
    def embed_batch(
        self,
        texts: List[str],
        batch_size: int = 32,
        normalize: bool = True,
        show_progress: bool = False
    ) -> np.ndarray:
        """
        Generate embeddings for large batch of texts.
        
        Args:
            texts: List of texts
            batch_size: Batch size for processing
            normalize: Whether to L2-normalize
            show_progress: Show progress bar
            
        Returns:
            Numpy array of shape (n_texts, 768)
        """
        if not texts:
            raise EmbeddingError("No texts provided for batch embedding")
        
        all_embeddings = []
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            embeddings = self.embed(batch, normalize=normalize)
            all_embeddings.append(embeddings)
            
            if show_progress:
                logger.info(f"Embedded {min(i + batch_size, len(texts))}/{len(texts)} texts")
        
        return np.vstack(all_embeddings)
    
    def similarity(
        self,
        text1: str,
        text2: str
    ) -> float:
        """
        Compute cosine similarity between two texts.
        
        Args:
            text1: First text
            text2: Second text
            
        Returns:
            Similarity score in [-1, 1]
        """
        embeddings = self.embed([text1, text2], normalize=True)
        return float(np.dot(embeddings[0], embeddings[1]))
    
    @staticmethod
    def _normalize(embeddings: np.ndarray) -> np.ndarray:
        """L2-normalize embeddings"""
        norms = np.linalg.norm(embeddings, axis=1, keepdims=True)
        norms = np.maximum(norms, 1e-12)  # Avoid division by zero
        return embeddings / norms
    
    def get_dimension(self) -> int:
        """Get embedding dimension"""
        return self.dimension
    
    def __repr__(self) -> str:
        return f"BGEEmbedder(model_path='{self.model_path}', device='{self.device}', dimension={self.dimension})"


# Singleton instance
_embedder: Optional[BGEEmbedder] = None


def get_embedder() -> BGEEmbedder:
    """Get global BGE embedder instance (singleton)"""
    global _embedder
    if _embedder is None:
        _embedder = BGEEmbedder()
    return _embedder
