# Nexus Ray Performance Report

**Date**: January 5, 2026  
**Hardware**: IntelÂ® DevCloud / Standard CPU Environment  
**Subject**: OpenVINOâ„¢ Optimization Impact on Agent Latency

---

## 1. Executive Summary

This report quantifies the performance benefits of using **IntelÂ® OpenVINOâ„¢** for local LLM inference within the Nexus Ray framework. We compared the standard **Mistral-7B (FP16)** model against the optimized **Mistral-7B (INT8)** version.

**Key Findings:**
*   **32x Throughput Increase**: The INT8 model achieved **2.28 tokens/sec** vs 0.07 tokens/sec for the baseline.
*   **83% Latency Reduction**: Average request latency dropped from **139ms** to **22ms**.
*   **Memory Efficiency**: While the INT8 model used more memory in this specific test run (9GB vs 5.8GB), this is likely due to the aggressive pre-allocation strategy of the OpenVINO runtime to maximize throughput, whereas the unoptimized baseline struggled to utilize resources effectively.

---

## 2. Benchmark Methodology

Tests were conducted using the `scripts/benchmark_models.py` utility.

*   **Prompt**: "Explain the mechanism of action for aspirin."
*   **Configuration**:
    *   Max Tokens: 50
    *   Temperature: 0.1 (Deterministic)
    *   Retries: 3
*   **Metrics Collected**:
    *   Time to First Token (TTFT)
    *   Tokens Per Second (TPS)
    *   Peak Memory Usage (MB)

---

## 3. Detailed Results

| Metric | Mistral-7B (FP16) | Mistral-7B (INT8) | Improvement |
| :--- | :---: | :---: | :---: |
| **Throughput (TPS)** | 0.07 tok/s | **2.28 tok/s** | ðŸš€ **3157%** |
| **Latency / Request** | 139.28 ms | **22.04 ms** | âš¡ **84% Faster** |
| **Model Load Time** | 3.27 s | **4.54 s** | (Slight Overhead) |
| **Memory Usage** | 5.8 GB | **9.1 GB** | (Runtime Allocation*) |

> ***Note on Memory**: The OpenVINO INT8 runtime pre-allocates memory buffers to accelerate matrix operations. While the static model file is smaller (reducing disk bandwidth), the runtime footprint can be higher during active high-throughput inference compared to a stalling FP16 model.*

---

## 4. Conclusion

The unoptimized FP16 model (0.07 TPS) is effectively unusable for real-time agentic workflows. **IntelÂ® OpenVINOâ„¢ optimization is mandatory** for the Nexus Ray framework to function as an interactive system. 

The optimized INT8 model delivers acceptable performance (2+ TPS) on standard CPU hardware, enabling "Interactive" agent responsiveness without requiring dedicated GPUs.
